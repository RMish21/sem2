{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4848f481",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\python311\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (2.9.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (4.57.3)\n",
      "Requirement already satisfied: jiwer in c:\\python311\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: soundfile in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (0.13.1)\n",
      "Collecting librosa\n",
      "  Downloading librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "     -------------------------------------- 260.7/260.7 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: filelock in c:\\python311\\lib\\site-packages (from torch) (3.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\python311\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\python311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\python311\\lib\\site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\python311\\lib\\site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python311\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\python311\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\python311\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\python311\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\python311\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python311\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: click>=8.1.8 in c:\\python311\\lib\\site-packages (from jiwer) (8.1.8)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in c:\\python311\\lib\\site-packages (from jiwer) (3.14.3)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (from soundfile) (2.0.0)\n",
      "Collecting audioread>=2.1.9\n",
      "  Downloading audioread-3.1.0-py3-none-any.whl (23 kB)\n",
      "Collecting numba>=0.51.0\n",
      "  Downloading numba-0.63.1-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "     ---------------------------------------- 2.7/2.7 MB 24.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python311\\lib\\site-packages (from librosa) (1.16.2)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in c:\\python311\\lib\\site-packages (from librosa) (1.7.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\python311\\lib\\site-packages (from librosa) (1.5.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (from librosa) (5.2.1)\n",
      "Collecting pooch>=1.1\n",
      "  Downloading pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.6/64.6 kB ? eta 0:00:00\n",
      "Collecting soxr>=0.3.2\n",
      "  Downloading soxr-1.0.0-cp311-cp311-win_amd64.whl (173 kB)\n",
      "     ------------------------------------- 173.8/173.8 kB 10.9 MB/s eta 0:00:00\n",
      "Collecting lazy_loader>=0.1\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Collecting msgpack>=1.0\n",
      "  Downloading msgpack-1.1.2-cp311-cp311-win_amd64.whl (71 kB)\n",
      "     ---------------------------------------- 71.6/71.6 kB 3.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pycparser in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: colorama in c:\\python311\\lib\\site-packages (from click>=8.1.8->jiwer) (0.4.6)\n",
      "Collecting llvmlite<0.47,>=0.46.0dev0\n",
      "  Downloading llvmlite-0.46.0-cp311-cp311-win_amd64.whl (38.1 MB)\n",
      "     ---------------------------------------- 38.1/38.1 MB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\users\\anura\\appdata\\roaming\\python\\python311\\site-packages (from pooch>=1.1->librosa) (4.5.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python311\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python311\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\python311\\lib\\site-packages (from requests->transformers) (2025.8.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python311\\lib\\site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\python311\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Installing collected packages: pydub, soxr, msgpack, llvmlite, lazy_loader, audioread, pooch, numba, librosa\n",
      "Successfully installed audioread-3.1.0 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.46.0 msgpack-1.1.2 numba-0.63.1 pooch-1.8.2 pydub-0.25.1 soxr-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --user torch torchaudio transformers jiwer soundfile librosa pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0d6dfdb-ec5d-424e-af01-a1fd64d7747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model...\n",
      "Processing 8 audio file(s)...\n",
      "Error processing audio assets/audio.wav: TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function.\n",
      "Failed to load: assets/audio.wav\n",
      "Error processing audio assets/audio 2.wav: TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function.\n",
      "Failed to load: assets/audio 2.wav\n",
      "Error processing audio assets/consultation.wav: TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function.\n",
      "Failed to load: assets/consultation.wav\n",
      "Error processing audio assets/prescription.wav: TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function.\n",
      "Failed to load: assets/prescription.wav\n",
      "Error processing audio assets/diagnosis.wav: TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function.\n",
      "Failed to load: assets/diagnosis.wav\n",
      "Error processing audio assets/vitals.wav: TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function.\n",
      "Failed to load: assets/vitals.wav\n",
      "Error processing audio assets/symptoms.wav: TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function.\n",
      "Failed to load: assets/symptoms.wav\n",
      "Error processing audio assets/test_results.wav: TorchCodec is required for load_with_torchcodec. Please install torchcodec to use this function.\n",
      "Failed to load: assets/test_results.wav\n",
      "No files processed successfully\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from jiwer import wer, cer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_grounds_truth(file_path):\n",
    "    grounds_truths = {}\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return grounds_truths\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            if \"|\" in line:\n",
    "                audio_file, transcription = line.split(\"|\", 1)\n",
    "                audio_file = audio_file.strip() or \"audio.flac\"\n",
    "            else:\n",
    "                audio_file = \"audio.flac\"\n",
    "                transcription = line\n",
    "            \n",
    "            grounds_truths[audio_file] = transcription.strip()\n",
    "    \n",
    "    return grounds_truths\n",
    "\n",
    "def process_audio(file_path):\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "        \n",
    "        # Convert to mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Resample to 16kHz\n",
    "        if sr != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "        \n",
    "        # Normalize\n",
    "        waveform = waveform / torch.max(torch.abs(waveform))\n",
    "        \n",
    "        return waveform\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing audio {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def transcribe(processor, model, audio):\n",
    "    audio_array = audio.squeeze().numpy()\n",
    "    \n",
    "    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    \n",
    "    # Set Hindi language\n",
    "    forced_decoder_ids = processor.get_decoder_prompt_ids(\n",
    "        language=\"hindi\", \n",
    "        task=\"transcribe\"\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(\n",
    "            inputs[\"input_features\"],\n",
    "            forced_decoder_ids=forced_decoder_ids,\n",
    "            max_new_tokens=440,\n",
    "            num_beams=5,\n",
    "            do_sample=False\n",
    "        )\n",
    "    \n",
    "    transcription = processor.batch_decode(\n",
    "        predicted_ids, \n",
    "        skip_special_tokens=True\n",
    "    )[0]\n",
    "    \n",
    "    return transcription.strip()\n",
    "\n",
    "def evaluate_asr():\n",
    "    # Load model\n",
    "    print(\"Loading Whisper model...\")\n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\")\n",
    "    model.eval()\n",
    "    \n",
    "    # Load ground truth\n",
    "    grounds_truths = load_grounds_truth(\"grounds_truth.txt\")\n",
    "    if not grounds_truths:\n",
    "        print(\"No grounds truth found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing {len(grounds_truths)} audio file(s)...\")\n",
    "    \n",
    "    total_wer = 0\n",
    "    total_cer = 0\n",
    "    count = 0\n",
    "    \n",
    "    for audio_file, gt_text in grounds_truths.items():\n",
    "        if not os.path.exists(audio_file):\n",
    "            print(f\"File not found: {audio_file}\")\n",
    "            continue\n",
    "        \n",
    "        audio = process_audio(audio_file)\n",
    "        if audio is None:\n",
    "            print(f\"Failed to load: {audio_file}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            predicted = transcribe(processor, model, audio)\n",
    "            \n",
    "            wer_score = wer(gt_text, predicted)\n",
    "            cer_score = cer(gt_text, predicted)\n",
    "            \n",
    "            total_wer += wer_score\n",
    "            total_cer += cer_score\n",
    "            count += 1\n",
    "            \n",
    "            print(f\"\\nFile: {audio_file}\")\n",
    "            print(f\"Predicted: {predicted}\")\n",
    "            print(f\"Actual: {gt_text}\")\n",
    "            print(f\"WER: {wer_score:.3f} | CER: {cer_score:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error transcribing {audio_file}: {e}\")\n",
    "    \n",
    "    # Results\n",
    "    if count > 0:\n",
    "        \n",
    "        print(\"RESULTS\")\n",
    "        \n",
    "        print(f\"Average WER: {total_wer/count:.3f}\")\n",
    "        print(f\"Average CER: {total_cer/count:.3f}\")\n",
    "        \n",
    "        if total_wer/count < 0.2:\n",
    "            print(\"Performance: Good\")\n",
    "        elif total_wer/count < 0.4:\n",
    "            print(\"Performance: Good\")\n",
    "        else:\n",
    "            print(\"Performance: Fair\")\n",
    "    else:\n",
    "        print(\"No files processed successfully\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_asr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
