{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0d6dfdb-ec5d-424e-af01-a1fd64d7747e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model...\n",
      "Processing 1 audio file(s)...\n",
      "\n",
      "File: audio.flac\n",
      "Predicted: हलो मेरा नाम मुहमद अथर है मुझे तीन दिन से खासी और जुगाम की शिकायत हो रही है मेरी बॉड़ी में भी पेल हो रहा है और गले में खराशें सी लग रही है साथी साथ सर भी भारी भारी रह रहा है तो क्या मुझे कोविड है या फिर कुछ और बीमारी होने का\n",
      "Actual: हेलो मेरा नाम मोहम्मद अतर है मुझे तीन दिन से खांसी और ज़ुकाम की शिकायत हो रही है मेरी बॉडी में भी पेन हो रहा है और गले में खराशे सी लग रही हैं साथ ही साथ सर भी भारी भारी रह रहा है तो क्या मुझे कोविड है या फिर कुछ और बीमारी होने का\n",
      "WER: 0.196 | CER: 0.061\n",
      "RESULTS\n",
      "Average WER: 0.196\n",
      "Average CER: 0.061\n",
      "Performance: Good\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from jiwer import wer, cer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def load_grounds_truth(file_path):\n",
    "    grounds_truths = {}\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        return grounds_truths\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            if \"|\" in line:\n",
    "                audio_file, transcription = line.split(\"|\", 1)\n",
    "                audio_file = audio_file.strip() or \"audio.flac\"\n",
    "            else:\n",
    "                audio_file = \"audio.flac\"\n",
    "                transcription = line\n",
    "            \n",
    "            grounds_truths[audio_file] = transcription.strip()\n",
    "    \n",
    "    return grounds_truths\n",
    "\n",
    "def process_audio(file_path):\n",
    "    try:\n",
    "        waveform, sr = torchaudio.load(file_path)\n",
    "        \n",
    "        # Convert to mono\n",
    "        if waveform.shape[0] > 1:\n",
    "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
    "        \n",
    "        # Resample to 16kHz\n",
    "        if sr != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "            waveform = resampler(waveform)\n",
    "        \n",
    "        # Normalize\n",
    "        waveform = waveform / torch.max(torch.abs(waveform))\n",
    "        \n",
    "        return waveform\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def transcribe(processor, model, audio):\n",
    "    audio_array = audio.squeeze().numpy()\n",
    "    \n",
    "    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "    \n",
    "    # Set Hindi language\n",
    "    forced_decoder_ids = processor.get_decoder_prompt_ids(\n",
    "        language=\"hindi\", \n",
    "        task=\"transcribe\"\n",
    "    )\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model.generate(\n",
    "            inputs[\"input_features\"],\n",
    "            forced_decoder_ids=forced_decoder_ids,\n",
    "            max_new_tokens=440,\n",
    "            num_beams=5,\n",
    "            do_sample=False\n",
    "        )\n",
    "    \n",
    "    transcription = processor.batch_decode(\n",
    "        predicted_ids, \n",
    "        skip_special_tokens=True\n",
    "    )[0]\n",
    "    \n",
    "    return transcription.strip()\n",
    "\n",
    "def evaluate_asr():\n",
    "    # Load model\n",
    "    print(\"Loading Whisper model...\")\n",
    "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-large-v3\")\n",
    "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-large-v3\")\n",
    "    model.eval()\n",
    "    \n",
    "    # Load ground truth\n",
    "    grounds_truths = load_grounds_truth(\"grounds_truth.txt\")\n",
    "    if not grounds_truths:\n",
    "        print(\"No grounds truth found!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Processing {len(grounds_truths)} audio file(s)...\")\n",
    "    \n",
    "    total_wer = 0\n",
    "    total_cer = 0\n",
    "    count = 0\n",
    "    \n",
    "    for audio_file, gt_text in grounds_truths.items():\n",
    "        if not os.path.exists(audio_file):\n",
    "            print(f\"File not found: {audio_file}\")\n",
    "            continue\n",
    "        \n",
    "        audio = process_audio(audio_file)\n",
    "        if audio is None:\n",
    "            print(f\"Failed to load: {audio_file}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            predicted = transcribe(processor, model, audio)\n",
    "            \n",
    "            wer_score = wer(gt_text, predicted)\n",
    "            cer_score = cer(gt_text, predicted)\n",
    "            \n",
    "            total_wer += wer_score\n",
    "            total_cer += cer_score\n",
    "            count += 1\n",
    "            \n",
    "            print(f\"\\nFile: {audio_file}\")\n",
    "            print(f\"Predicted: {predicted}\")\n",
    "            print(f\"Actual: {gt_text}\")\n",
    "            print(f\"WER: {wer_score:.3f} | CER: {cer_score:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error transcribing {audio_file}: {e}\")\n",
    "    \n",
    "    # Results\n",
    "    if count > 0:\n",
    "        \n",
    "        print(\"RESULTS\")\n",
    "        \n",
    "        print(f\"Average WER: {total_wer/count:.3f}\")\n",
    "        print(f\"Average CER: {total_cer/count:.3f}\")\n",
    "        \n",
    "        if total_wer/count < 0.2:\n",
    "            print(\"Performance: Good\")\n",
    "        elif total_wer/count < 0.4:\n",
    "            print(\"Performance: Good\")\n",
    "        else:\n",
    "            print(\"Performance: Fair\")\n",
    "    else:\n",
    "        print(\"No files processed successfully\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_asr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c81c0f-fe1c-447e-93e1-18bbaca51c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
